---
title: "HPDataAnalysis"
author: "Giorgio Cannavacciuolo"
date: '2023-12-12'
output: html_document
---
###Honours Project - Data Analysis

In the present script, I carry out all the data wrangling, preparation, analyses, and visualisations that I have either entirely or partially used for my Investigative Honours Project write-up, focusing on the Theta-Induced Memory Enhancement Effect (TIME), with respect to its longevity, sleep modulation, and the impact of potential peri-encoding confounds. The structure of the script will try to follow the structure of the Results section of the report for clarity. For any questions, please do not hesitate to contact the author of the script and report. 

##Data Preparation
Prior to any analysis, I conduct data preparation steps including loading libraries and data, merging them into a comprehensive dataset, and renaming to enhance clarity.

#Loading libraries needed
```{r}
library(tidyverse)
```

#Loadind Short Delay Memory Data 
```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/shortrecall"

# Get a list of all CSV files in the directory

file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=block-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("st", x, "_", y), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

# Combine all data into a single dataset
st <- mget(ls(pattern = "^st\\d+_\\d+$")) %>% bind_rows(.id = "file_id")
```

#Loading Long Delay Memory Data
```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/longrecall"

# Get a list of all CSV files in the directory

file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=block-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("lt", x, "_", y), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

# Combine all data into a single dataset
lt <- mget(ls(pattern = "^lt\\d+_\\d+$")) %>% bind_rows(.id = "file_id")
```

#Loading sleep results for short and long
```{r}
sleep_short <- read_csv("Sleep_short.csv")
sleep_long <- read_csv("Sleep_long.csv")
```
#Adding a column for delay
```{r}
st$delay <- "short"
lt$delay <- "long"
```

#Renaming column headings for clarity in st and lt 
```{r}
st <- st %>% rename(phase_word = `testrespMat_ 6`, phase = `testrespMat_ 8`, correct = testrespMat_14, response = testrespMat_15, participant = `testrespMat_ 1`)

lt <- lt %>% rename(phase_word = `testrespMat_ 6`, phase = `testrespMat_ 8`, correct = testrespMat_14, response = testrespMat_15, participant = `testrespMat_ 1`)

#Please note that testrespMat columns were renamed based on a ReadMe file containing paradigm script's specification
```

----------------------------------------------------------------------------

##Data wrangling
Here, I start rearranging the data to match my testing aims, hence computing the number of correct trials (recall accuracy) based on our initial data.

#Creating a column for correct responses in short and long delay memory
```{r}
st <- st %>% mutate(correct_response = (response == correct))

lt <- lt %>% mutate(correct_response = (response == correct))
```

#Counting right answers for each participant and each phase offset (short & long), then merging together
```{r}
correct_counts_st <- st %>% group_by(participant, phase_word, phase, delay) %>%
  summarise(correct_responses = sum(correct_response == TRUE, na.rm = TRUE))
correct_counts_st <- correct_counts_st %>% mutate(correctpercentage = ((correct_responses/16)))

correct_counts_lt <- lt %>% group_by(participant, phase_word, phase, delay) %>%
  summarise(correct_responses = sum(correct_response == TRUE, na.rm = TRUE))
correct_counts_lt <- correct_counts_lt %>% mutate(correctpercentage = ((correct_responses/16)))

#Please note that 16 here reflects the number of trials per phase offset across the two blocks.

general <- rbind(correct_counts_lt, correct_counts_st)
```

#Merging together sleep and memory data
```{r}
sleep <- rbind(sleep_long, sleep_short)
colnames(sleep)[colnames(sleep) == "Participant"] <- "participant"
colnames(sleep)[colnames(sleep) == "Delay"] <- "delay"

general_sleep <- merge(general, sleep, by = c("participant", "delay"))
```

----------------------------------------------------------------------------

Now that the data are ready, we can proceed with the Results structure.

##Section 3.1 - Assumption Check

#Data preparation and Assumptions Check
```{r}
hist(correct_counts_st$correctpercentage, xlab = "Recall Accuracy") #Included in Appendix


hist(correct_counts_lt$correctpercentage, xlab = "Recall Accuracy") #Included in Appendix


shapiro.test(correct_counts_st$correctpercentage)
shapiro.test(correct_counts_lt$correctpercentage)
bartlett.test(general$correctpercentage, general$phase)

#Data must be filtered per phase for t_test() function
st_0 <- correct_counts_st %>% filter(phase_word == 'zero')
st_180 <- correct_counts_st %>% filter(phase_word == 'oneeighty')

lt_0 <- correct_counts_lt %>% filter(phase_word == 'zero')
lt_180 <- correct_counts_lt %>% filter(phase_word == 'oneeighty')
```

##Section 3.2 and 3.3 - The TIME effect replication in short delay recall + The TIME effect longevity across 24 hours

#Descriptive Statistics

#Descriptives - by phase and delay (Table 2)
```{r}
#Calculating descriptive statistics of recall accuracy across phase and delay conditions

descriptives_correct <- general %>% group_by(phase_word, delay) %>% summarise(mean_correct = mean(correctpercentage), sd_correct = sd(correctpercentage), sem = sd_correct/sqrt(24), min = min(correctpercentage), max = max(correctpercentage), ci_lower = t.test(correctpercentage)$conf.int[1],
    ci_upper = t.test(correctpercentage)$conf.int[2])

#Measures of central tendency, spread, and error are included

#Note that when computing the standard error of the mean, N here is 24 because each participant in each group has two average observations (one for 0°, one for 180°).This would lead to 48 averages (24 per phase) in the short delay and 48 (24 per phase) in the long delay. Since the standard error of the mean is specific to the mean recall accuracy for each phase within each delay group, then we should divide by 24.
```

#Inferentials - t-test and 2x2 ANOVA

Aim 1: Paired T-test (phase x recall accuracy in short delay)
```{r}
t_test_st <- t.test(st_0$correctpercentage, st_180$correctpercentage, paired = TRUE)

#Paired because all short-term participants (within-subject)

print(t_test_st)

library(lsr) #for effect size
cohensD(st_0$correctpercentage, st_180$correctpercentage)
```

Aim 2: Paired T-test (phase x recall accuracy in long delay)
```{r}
t_test_lt <- t.test(lt_0$correctpercentage, lt_180$correctpercentage, paired = TRUE)

#Paired because all long-term participants (within-subject)

print(t_test_lt)

cohensD(lt_0$correctpercentage, lt_180$correctpercentage)
```

Aim 2.1: 2x2 ANOVA (phase and delay x recall accuracy)
```{r}
anova_phase_delay <- aov(correctpercentage ~ delay * phase_word, data = general)
summary(anova_phase_delay)

library(lsr) #Effect Size
etaSquared(anova_phase_delay)

#ANOVA testing the effect of the individual factors AND their interaction (*)

TukeyHSD(anova_phase_delay) 
```

#Section 3.3.1 - Chance level performance control
```{r}
# Set the probability of success for a four-option task
probability_of_success <- 1/4

# Number of trials
n <- 16

# Calculate chance level
chance_level <- n * probability_of_success

# Calculate 95% confidence interval for chance level
confidence_interval <- binom.test(chance_level, n, conf.level = 0.95)$conf.int

# Print results
cat("Chance Level:", chance_level, "\n")
cat("95% Confidence Interval:", confidence_interval[1], "-", confidence_interval[2], "\n")

#Find participants who performed at chance level or below
general_filtered <- general %>% filter(correct_responses > 5)

#The last object contains data from participants exclusively performing above chance level
```

#Rerun analyses filtered for participant performing at chance level
```{r}
descriptives_filtered <- general_filtered %>% group_by(phase_word, delay) %>% summarise(mean_correct = mean(correctpercentage), sd_correct = sd(correctpercentage), sem = sd_correct/sqrt(48), min = min(correctpercentage), max = max(correctpercentage), ci_lower = t.test(correctpercentage)$conf.int[1],
    ci_upper = t.test(correctpercentage)$conf.int[2])


anova_filtered <- aov(correctpercentage ~ delay * phase_word, data = general_filtered)
summary(anova_filtered)

#TukeyHSD(anova_filtered) #No need as ANOVA is still non-significant

etaSquared(anova_filtered)
```

#Visualisation - Figure 4 + alternative visualisations

Computing mean to superimpose
```{r}
mean_data <- general %>%
  group_by(delay, phase) %>%
  summarise(mean_correctpercentage = mean(correctpercentage))

mean_data_filtered <- general_filtered %>%
  group_by(delay, phase) %>%
  summarise(mean_correctpercentage = mean(correctpercentage))
```

Final graph with two panels and distribution plots (unfiltered)
```{r}
library(see) #For half violins with dots geom_violindot()


panel <- general %>% ggplot(
       mapping = aes(x = factor(phase), y = correctpercentage)) +
  geom_violindot(aes(fill = factor(phase)),
                 dots_alpha = 0.8,
                 dots_size = 0.2,
                 position_dots = position_dodge(0.1),
                 flip = c(3)) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 2) +
  geom_line(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("short" = "Short Delay (5min)",
      "long" = "Long Delay (24h)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"),
        strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1)) + scale_fill_manual(values = c("#a8c4e0", "#495669")) + guides(fill = FALSE)

ggsave("panel.jpg")
```
Final graph with two panels and distribution plots (filtered)
```{r}
library(see) #For half violins

panel_filter <- ggplot(data = general_filtered,
       mapping = aes(x = factor(phase), y = correctpercentage)) +
  geom_violindot(aes(fill = factor(phase)),
                 dots_alpha = 0.8,  # Adjust transparency
                 dots_size = 0.2,   # Adjust size
                 position_dots = position_dodge(0.1),
                 flip = c(3)) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data_filtered, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 2) +
  geom_line(data = mean_data_filtered, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"),
        strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1)) + scale_y_continuous(breaks = c(0.2, 0.4, 0.6, 0.8, 1)) + scale_fill_manual(values = c("#a8c4e0", "#495669")) + guides(fill = FALSE)

ggsave("panel_filter.jpg")

```
ALternative faceted visualisations
```{r}
general %>%
  ggplot(aes(x = factor(phase), y = correctpercentage)) +
  geom_point(alpha = 0.2) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 3) +
  geom_line(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1))

#Graph without distribution plots - not included
```

```{r}
general %>%
  ggplot(aes(x = factor(phase), y = correctpercentage)) +
  geom_point(alpha = 0.2) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 3) +
  geom_line(data = mean_data, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  geom_violin(aes(x = factor(phase), y = correctpercentage), position = "identity", scale = "width", alpha = 0.5, fill = "lightblue") +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1))

#Graph with overlied distribution graph - not included
```

Alternative visualisations individually for short and long  delay
```{r}
correct_counts_st %>% ggplot(aes(x = factor(phase), y = correctpercentage, group = participant)) + geom_point(alpha = 0.2) + geom_line(alpha = 0.2) + scale_y_continuous(breaks = seq(0, 1, by = 0.2)) + theme_minimal() + xlab("Phase offset (degree)") + ylab("Accuracy in recall task") + theme(axis.text = element_text(size = 16),  
        axis.title = element_text(size = 18, face = "bold")) + scale_x_discrete(expand = c(0.1, 0.1))

#Not included 
```
```{r}
correct_counts_lt %>% ggplot(aes(x = factor(phase), y = correctpercentage, group = participant)) + geom_point(alpha = 0.2) + geom_line(alpha = 0.2) + scale_y_continuous(breaks = seq(0, 1, by = 0.2)) + theme_minimal() + xlab("Phase offset (degree)") + ylab("Accuracy in recall task") + theme(axis.text = element_text(size = 16),  
        axis.title = element_text(size = 18, face = "bold")) + scale_x_discrete(expand = c(0.1, 0.1))

#Not included
```

##Section 3.3.2: Exploratory Analyses - Nested approach
```{r}
#Here we create a non-averaged (nested) dataset by analysis participants' performed trial by trial rather than in percentage. The dependent variable is binomial (TRUE/FALSE).

general_nested <- rbind(st, lt) 

library(lme4) #For mixed effects 

nested_model_interact <- glmer(correct_response ~ phase_word * delay + (1 + phase_word + delay | participant), data = general_nested, family = "binomial") 
summary(nested_model_interact)

#Non-interacting model

nested_model <- glmer(correct_response ~ phase_word + delay + (1 + phase_word + delay | participant), data = general_nested, family = "binomial") 

summary(nested_model)
```

---------------------------------------------------------------------------

##Section 3.4 - The TIME effect and sleep – subjective quality and quantity effects

#Descriptives
```{r}
descriptives_sleepquantity <- general_sleep %>% group_by(delay) %>% summarise(meanquantity = mean(Quantity), sdquantity = sd(Quantity), sem = sdquantity/sqrt(24), min = min(Quantity), max = max(Quantity), ci_lower = t.test(Quantity)$conf.int[1],
    ci_upper = t.test(Quantity)$conf.int[2])
```

#Inferential 
Aim 3.1: 4x2x2 MANOVA (sleep quality, delay, phase x recall accuracy)
```{r}
#ANOVA without interactions
SleepQuality_anova <- aov(correctpercentage ~ delay + phase_word + Quality, data = general_sleep)

summary(SleepQuality_anova)

etaSquared(SleepQuality_anova)

#ANOVA without interactions
SleepQuality_anovainteract <- aov(correctpercentage ~ delay + phase_word * Quality, data = general_sleep)

summary(SleepQuality_anovainteract)

#all non-significant interactions
#TukeyHSD(SleepQuality_anova) #Not needed as ANOVA is non-significant.
```

Aim 3.2:GLM (sleep quantity, delay, and phase)

```{r}
quantity_model <- lm(correctpercentage ~ Quantity + delay + phase_word, data = general_sleep)

summary(quantity_model)
```
```{r}
quantity_model_diff <- lm(difference ~ Quantity + delay, data = difference_sleep)

summary(quantity_model_diff)
```

```{r}
quantity_model_interact <- lm(correctpercentage ~ Quantity * delay * phase_word, data = general_sleep)

summary(quantity_model_interact)
```
```{r}
quantity_model_semiinteract <- lm(correctpercentage ~ Quantity + delay * phase_word, data = general_sleep)

summary(quantity_model_semiinteract)
```

```{r}
quantity_model_simpler <- lm(correctpercentage ~ Quantity + phase_word, data = general_sleep)

summary(quantity_model_simpler)
```
```{r}
general_sleep_short <- general_sleep %>% filter(delay == "short")

quantity_model_onlyshort <- lm(correctpercentage ~ Quantity + phase_word, data = general_sleep_short)

summary(quantity_model_onlyshort)

general_sleep_long <- general_sleep %>% filter(delay == "long")

quantity_model_onlylong <- lm(correctpercentage ~ Quantity + phase_word, data = general_sleep_long)

summary(quantity_model_onlylong)

#All models are non-significant
```

#Visualisation

Visualising Aim 3
```{r}
difference_sleep %>% ggplot(aes(x = Quality, y = difference)) + geom_point() + geom_boxplot() + facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal()  +
  xlab("Rating") +
  ylab("Recall difference (0° - 180°)") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) 
```

Figure 6
```{r}
mean_data_quality <- general_sleep %>%
  group_by(delay, phase, Quality) %>%
  summarise(mean_correctpercentage = mean(correctpercentage))

#quality <- 
  ggplot(general_sleep, aes(x = as.factor(phase), y = correctpercentage)) +
  geom_point(alpha = 0.2) +
  geom_line(alpha = 0.2, aes(group = participant)) +  
  geom_point(data = mean_data_quality, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 2) +
  geom_line(data = mean_data_quality, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_grid(delay ~ Quality, labeller = labeller(delay = 
    c("short" = "Short Delay (5min)",
      "long" = "Long Delay (24h)"))) +  # Facet wrap according to delay
  xlab("Phase Offset (degree)") +
  ylab("Accuracy in Recall Task") +
  theme_minimal() +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1)) 

ggsave("quality.png")
```
Figure 7
```{r}
Quantity <- difference_sleep %>% ggplot(aes(x = Quantity, y = difference)) + geom_point() + geom_smooth(method = "lm", se = TRUE) + facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal()  +
  xlab("Sleep quantity (hours)") +
  ylab("Recall difference (0° - 180°)") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) 

ggsave("Quantity.png")
```



```{r}
#quantity <- 
  
  ggplot(general_sleep, aes(x = Quantity, y = correctpercentage, color = as.factor(phase))) +
  geom_point() + geom_smooth(method = "lm", se = TRUE, aes(group = phase_word)) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Sleep quantity (hours)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) + labs(color = "Phase offset (degrees)")

ggsave("quantity.png")
```


```{r}
#Alternative visualisation - not used
general_sleep %>% ggplot(aes(x = as.factor(phase), y = correctpercentage, colour = Quality)) + geom_boxplot() + facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in recall task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"), strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1))
```

----------------------------------------------------------------------------

##Section 3.5 - Perceptual level confound

#Loading and preparing data

```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/shortsync"

# Get a list of all CSV files in the directory

file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=Sync-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("sync_s_", x), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

#Merging them altogether
sync_s <- mget(ls(pattern = "^sync_s_\\d+$")) %>% bind_rows(.id = "file_id")

```

```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/longsync"

# Get a list of all CSV files in the directory

file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=Sync-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("sync_l_", x), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

#Merging them altogether
sync_l <- mget(ls(pattern = "^sync_l_\\d+$")) %>% bind_rows(.id = "file_id")
```

```{r}
sync_s$delay <- "short"
sync_l$delay <- "long"

sync <- rbind(sync_s, sync_l)

sync <- sync %>% rename(phase_word = `respMat_ 5`, phase = `respMat_ 8`,  correct = respMat_10, participant = `respMat_ 1`, response = respMat_11)

sync <- sync %>% mutate(correct_response = (response == correct))

sync_counts <- sync %>% group_by(participant, phase_word, phase, delay) %>%
  summarise(correct_responses = sum(correct_response == TRUE, na.rm = TRUE)) %>% mutate(correctpercentage = ((correct_responses/8)))
```

#Descriptives 
```{r}
descriptives_sync <- sync_counts %>% group_by(phase_word, delay) %>% summarise(mean_correct = mean(correctpercentage), sd_correct = sd(correctpercentage), sem = sd_correct/sqrt(24), min = min(correctpercentage), max = max(correctpercentage), ci_lower = t.test(correctpercentage)$conf.int[1],
    ci_upper = t.test(correctpercentage)$conf.int[2])
```

#Inferentials
```{r}
anova_sync <- aov(correctpercentage ~ delay * phase_word, data = sync_counts)
summary(anova_sync)

TukeyHSD(anova_sync)

etaSquared(anova_sync)
```

#Visualisation
```{r}
mean_data_sync <- sync_counts %>%
  group_by(delay, phase) %>%
  summarise(mean_correctpercentage = mean(correctpercentage))

sync <- sync_counts %>% ggplot(aes(x = as.factor(phase), y = correctpercentage)) +
  geom_violindot((aes(fill = factor(phase))),
                dots_alpha = 0.8,  # Adjust transparency
                 dots_size = 0.2,   # Adjust size
                 position_dots = position_dodge(0.1),
                 flip = c(3)) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data_sync, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 2) +
  geom_line(data = mean_data_sync, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in synchronisation task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"),
        strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1)) + scale_fill_manual(values = c("#a8c4e0", "#495669")) + guides(fill = FALSE)

ggsave("sync.png")
```
#Chance level in synchrony
```{r}
# Set the probability of success for a four-option task
probability_of_success_1 <- 1/2

# Number of trials
n_1 <- 8

# Calculate chance level
chance_level_1 <- n_1 * probability_of_success_1

# Calculate 95% confidence interval for chance level
confidence_interval_1 <- binom.test(chance_level_1, n_1, conf.level = 0.95)$conf.int

# Print results
cat("Chance Level:", chance_level_1, "\n_1")
cat("95% Confidence Interval:", confidence_interval_1[1], "-", confidence_interval_1[2], "\n_1")

#Find participants who performed at chance level or below
sync_filtered <- sync_counts %>% filter(correct_responses > 5)

#No participant performed above chance level
anova_sync_filtered <- aov(correctpercentage ~ delay * phase_word, data = sync_filtered)
summary(anova_sync_filtered)

etaSquared(anova_sync_filtered)
```
```{r}
mean_data_sync_filtered <- sync_filtered %>%
  group_by(delay, phase) %>%
  summarise(mean_correctpercentage = mean(correctpercentage))

  sync_filtered %>% ggplot(aes(x = as.factor(phase), y = correctpercentage)) +
  geom_violindot((aes(fill = factor(phase))),
                dots_alpha = 0.8,  # Adjust transparency
                 dots_size = 0.2,   # Adjust size
                 position_dots = position_dodge(0.1),
                 flip = c(3)) +
  geom_line(alpha = 0.2, aes(group = participant)) +
  geom_point(data = mean_data_sync_filtered, aes(x = factor(phase), y = mean_correctpercentage), color = "red", size = 2) +
  geom_line(data = mean_data_sync_filtered, aes(x = factor(phase), y = mean_correctpercentage, group = 1), color = "red", size = 1) +
  facet_wrap(~delay, labeller = labeller(delay = 
    c("long" = "Long Delay (24h)",
      "short" = "Short Delay (5min)"))) +
  theme_minimal() +
  xlab("Phase offset (degree)") +
  ylab("Accuracy in synchronisation task") +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"),
        strip.text = element_text(size = 14)) +
  scale_x_discrete(expand = c(0.1, 0.1)) + scale_fill_manual(values = c("#a8c4e0", "#495669")) + guides(fill = FALSE)
```

------------------------------------------------------------------------------

##Section 3.7 - Exploratory Analyses - Emotional confounds analysis

#Data preparation and wrangling

Short Delay Ratings
```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/shortrating"

# Get a list of all CSV files in the directory
file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=block-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("rating_s", x, "_", y), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

# Combine all data into a single dataset
rating_s <- mget(ls(pattern = "^rating_s\\d+_\\d+$")) %>% bind_rows(.id = "file_id")
```

Long Delay Ratings
```{r}
# Set the directory path
directory_path <- "/Users/giorgiocannavacciuolo/Desktop/HonsProject/longrating"

# Get a list of all CSV files in the directory
file_list <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Define a function to read and name the files
read_and_name <- function(file_path) {
  # Extract x and y from the file name
  x <- str_extract(file_path, "(?<=subj)\\d+")
  y <- str_extract(file_path, "(?<=block-)\\d+")

  # Read the CSV file and name it
  read_csv(file_path) %>% assign(paste0("rating_l", x, "_", y), ., envir = .GlobalEnv)
}

# Use map to apply the function to each file in the list
file_list %>% map(read_and_name)

# Combine all data into a single dataset
rating_l <- mget(ls(pattern = "^rating_l\\d+_\\d+$")) %>% bind_rows(.id = "file_id")
```

Merged data 
```{r}
rating_s$delay <- "short"
rating_l$delay <- "long"
Rating <- rbind(rating_s, rating_l)
Rating <- Rating %>% rename(phase_word = `respMat_ 6`, phase = `respMat_ 8`,  rating = respMat_10, participant = `respMat_ 1`, movie = `respMat_ 5`, sound = `respMat_ 7`)

#Rating contains every trial of all eight rating blocks and the corresponding subjective ratings
```

#Rearranging general datasets to match column headings
```{r}
st_rating <- st %>% rename(movie = `testrespMat_ 5`, sound = `testrespMat_ 7`)
lt_rating <- lt %>% rename(movie = `testrespMat_ 5`, sound = `testrespMat_ 7`)
total <- rbind(st_rating, lt_rating)
#total contains all the trials by each participant and whether the given response was accurate (TRUE) or inaccurate (FALSE).

total_rating <- merge(total, Rating, by = c("participant", "movie", "sound", "phase", "delay"))

#total_rating_tidy <- total_rating %>% group_by(participant, rating, phase, delay) %>% summarise(correct_performance = sum(correct_response == TRUE), incorrect_performance = sum(correct_response == FALSE))

#total_rating_tidy contains the number of correctly recalled audiovisual pairs based on the rating, phase, and delay conditions.

```

#Inferentials
```{r}
total_rating_s <- total_rating %>% filter(delay == "short")
glm_rating_s <- glm(correct_response ~ as.factor(phase) * as.factor(rating), data = total_rating_s)

summary(glm_rating_s)
```

```{r}
library(lme4) #For mixed effects 

control_params <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))

model <- glmer(
  correct_response ~ as.factor(rating) * as.factor(phase) * delay +
    (1 + as.factor(phase) + delay + as.factor(rating) | participant),
  data = total_rating,
  family = binomial,
  control = control_params
)

summary(model)
```
```{r}
model <- glmer(
  correct_response ~ as.factor(rating) + as.factor(phase) + delay +
    (1 + as.factor(phase) + delay + as.factor(rating) | participant),
  data = total_rating,
  family = binomial,
  control = control_params
)

summary(model)
```

#Visualisations

```{r}
rating <- ggplot(total_rating, aes(x = factor(rating), fill = correct_response)) + geom_bar(position = "dodge", stat = "count") + facet_wrap(as.factor(phase) ~ delay, labeller = labeller(delay = c("short" = "Short Delay (5min)", "long" = "Long Delay (24h)")))  + theme_minimal() + ylab("Number of trials") + xlab("Subjective Rating") + scale_fill_manual(values = c("#a8c4e0", "#495669"), name = "Correct Response") + theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18, face = "bold"),
        strip.text = element_text(size = 14)) 

ggsave("rating.png")
```

```{r}
difference_st <- merge(st_0, st_180, by = "participant", suffixes = c("_st_0", "_st_180")) %>% mutate(difference = correctpercentage_st_0 - correctpercentage_st_180) %>% select(participant, difference)

difference_st$delay <- "short"

difference_lt <- merge(lt_0, lt_180, by = "participant", suffixes = c("_lt_0", "_lt_180")) %>% mutate(difference = correctpercentage_lt_0 - correctpercentage_lt_180) %>% select(participant, difference)

difference_lt$delay <- "long"

difference <- rbind(difference_st, difference_lt)

difference_sleep <- merge(difference, sleep, by = c("participant", "delay"))


```


